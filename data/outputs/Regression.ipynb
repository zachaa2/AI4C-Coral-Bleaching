{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0702481-592b-442c-80c7-5e8847256da2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f0702481-592b-442c-80c7-5e8847256da2",
    "outputId": "14fa8fb8-a181-4eb7-e426-c86b3cf963e8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef5c40fc-04c6-430d-b758-b841dbb76508",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef5c40fc-04c6-430d-b758-b841dbb76508",
    "outputId": "a716fefd-8b1b-4ee4-b2d5-6c980e0497a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "                                name        date location     label  \\\n",
      "657   CUR_CRA_040_20231018_T4_16.JPG  2023-10-18  Curacao   healthy   \n",
      "681   CUR_CRA_049_20231017_T3_14.JPG  2023-10-17  Curacao   healthy   \n",
      "729   CUR_CRA_060_20231016_T1_15.JPG  2023-10-16  Curacao   healthy   \n",
      "1092  CUR_CRA_110_20231031_T1_02.JPG  2023-10-31  Curacao   healthy   \n",
      "594   CUR_CRA_033_20231024_T3_05.JPG  2023-10-24  Curacao   healthy   \n",
      "...                              ...         ...      ...       ...   \n",
      "373   CUR_CRA_017_20231027_T5_13.JPG  2023-10-27  Curacao  bleached   \n",
      "859   CUR_CRA_080_20231103_T2_02.JPG  2023-11-03  Curacao  bleached   \n",
      "1025  CUR_CRA_100_20231101_T4_03.JPG  2023-11-01  Curacao  bleached   \n",
      "1279  CUR_CRA_119_20231023_T4_12.JPG  2023-10-23  Curacao  bleached   \n",
      "368   CUR_CRA_017_20231027_T5_01.JPG  2023-10-27  Curacao  bleached   \n",
      "\n",
      "     CoralReefWatch location  SST@90th_HS  \n",
      "657              abc_islands        29.95  \n",
      "681              abc_islands        30.21  \n",
      "729              abc_islands        29.86  \n",
      "1092             abc_islands        29.95  \n",
      "594              abc_islands        30.09  \n",
      "...                      ...          ...  \n",
      "373              abc_islands        30.20  \n",
      "859              abc_islands        30.20  \n",
      "1025             abc_islands        30.31  \n",
      "1279             abc_islands        30.12  \n",
      "368              abc_islands        30.20  \n",
      "\n",
      "[1068 rows x 6 columns]\n",
      "\n",
      "Test Set:\n",
      "                                name        date location     label  \\\n",
      "954   CUR_CRA_091_20231021_T5_01.JPG  2023-10-21  Curacao   healthy   \n",
      "925   CUR_CRA_090_20231102_T2_14.JPG  2023-11-02  Curacao   healthy   \n",
      "74    CUR_CRA_002_20231026_T4_01.JPG  2023-10-26  Curacao   healthy   \n",
      "1408  CUR_CRA_123_20231022_T5_05.JPG  2023-10-22  Curacao   healthy   \n",
      "1199  CUR_CRA_116_20231022_T1_09.JPG  2023-10-22  Curacao   healthy   \n",
      "...                              ...         ...      ...       ...   \n",
      "563   CUR_CRA_031_20231024_T1_12.JPG  2023-10-24  Curacao  bleached   \n",
      "170   CUR_CRA_005_20231026_T1_01.JPG  2023-10-26  Curacao  bleached   \n",
      "135   CUR_CRA_004_20231026_T1_02.JPG  2023-10-26  Curacao  bleached   \n",
      "1214  CUR_CRA_118_20231023_T1_10.JPG  2023-10-23  Curacao  bleached   \n",
      "376   CUR_CRA_019_20231027_T1_07.JPG  2023-10-27  Curacao  bleached   \n",
      "\n",
      "     CoralReefWatch location  SST@90th_HS  \n",
      "954              abc_islands        29.93  \n",
      "925              abc_islands        30.27  \n",
      "74               abc_islands        30.18  \n",
      "1408             abc_islands        29.96  \n",
      "1199             abc_islands        29.96  \n",
      "...                      ...          ...  \n",
      "563              abc_islands        30.09  \n",
      "170              abc_islands        30.18  \n",
      "135              abc_islands        30.18  \n",
      "1214             abc_islands        30.12  \n",
      "376              abc_islands        30.20  \n",
      "\n",
      "[459 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "\n",
    "    train_set = list()\n",
    "    test_set = list()\n",
    "\n",
    "    # Add proportionate data from each category to maintain the ratio of the overall dataset\n",
    "    for label in data['label'].unique():\n",
    "        label_data = data[data['label'] == label]\n",
    "\n",
    "        train_label_data, test_label_data = train_test_split(label_data, test_size=0.3, random_state=42)\n",
    "\n",
    "        # Append the splits\n",
    "        train_set.append(train_label_data)\n",
    "        test_set.append(test_label_data)\n",
    "\n",
    "    train_df = pd.concat(train_set)\n",
    "    test_df = pd.concat(test_set)\n",
    "\n",
    "    print(\"Training Set:\")\n",
    "    print(train_df, end=\"\\n\\n\")\n",
    "    print(\"Test Set:\")\n",
    "    print(test_df)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = split_dataset('images/Curacao Coral Reef Assessment 2023 CUR/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2198894f",
   "metadata": {
    "id": "2198894f"
   },
   "outputs": [],
   "source": [
    "class CoralDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_files = df['name'].tolist()\n",
    "        self.ssts = df[\"SST@90th_HS\"].to_numpy(dtype=np.float32)\n",
    "        self.labels = df[\"label\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = \"{}/images/Curacao Coral Reef Assessment 2023 CUR/{}/{}\".format(os.getcwd(), self.labels[idx], self.image_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        sst = self.ssts[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, sst\n",
    "\n",
    "# Resize images to match FashionMNIST format\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "training_data = CoralDataset(train_df, transform=transform)\n",
    "test_data = CoralDataset(test_df, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40d4e5b9-be61-4eb8-8f9d-fcc4b08fd329",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40d4e5b9-be61-4eb8-8f9d-fcc4b08fd329",
    "outputId": "174f8467-093c-4a58-9eba-b10d21e8e8ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class ResNetWithFC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetWithFC, self).__init__()\n",
    "\n",
    "        # Load a pre-trained ResNet model (e.g., ResNet18)\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "        # Modify the final fully connected layer\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0ca6b40-dd41-492f-8587-3e3f225aae7b",
   "metadata": {
    "id": "e0ca6b40-dd41-492f-8587-3e3f225aae7b"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06120167-a600-4a0c-812c-dbbc3cfaa27b",
   "metadata": {
    "id": "06120167-a600-4a0c-812c-dbbc3cfaa27b"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X).squeeze()\n",
    "        print(pred, y)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            # Commenting this out to reduce clutter in output\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42dfbbec-a089-41ea-b4e7-d90bcd2c9733",
   "metadata": {
    "id": "42dfbbec-a089-41ea-b4e7-d90bcd2c9733"
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, best_loss, best_model):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X).squeeze()\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "\n",
    "    print(f\"Test Error: Avg loss: {test_loss:>8f}\")\n",
    "\n",
    "    if test_loss<best_loss:\n",
    "      print(\"Found new best model with average test loss {}\\n\".format(test_loss))\n",
    "      best_loss = test_loss\n",
    "      best_model = model\n",
    "\n",
    "    return best_model, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11ce0d34-e9f3-4845-ac77-0b7da09d439f",
   "metadata": {
    "id": "11ce0d34-e9f3-4845-ac77-0b7da09d439f"
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "def train_model(lr, batch_size=32):\n",
    "  # Initialization for best loss set to a high value\n",
    "  best_loss = 100000\n",
    "  best_model = None\n",
    "\n",
    "  model = ResNetWithFC().to(device)\n",
    "\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "  train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "  test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "  for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "\n",
    "    best_model, best_loss = test(test_dataloader, model, loss_fn, best_loss, best_model)\n",
    "\n",
    "  print(\"Done!\")\n",
    "\n",
    "  return best_model, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ivpl8OR4jGyB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ivpl8OR4jGyB",
    "outputId": "ad35219f-3f83-40a3-f748-866f470db754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "tensor([-0.8937,  0.1686,  0.2749, -1.0925, -0.5593, -0.5054, -0.5729, -0.1538,\n",
      "        -1.0839, -0.4300, -0.3997, -0.6546, -0.2019, -0.0750, -0.4182,  0.0831,\n",
      "        -0.4167, -0.7566, -0.7901, -0.2507,  0.8245, -0.2011,  0.2457, -0.4136,\n",
      "        -0.5468, -0.1922, -0.5551,  0.0629, -0.4411, -0.4952, -0.1535, -0.5184],\n",
      "       grad_fn=<SqueezeBackward0>) tensor([29.9500, 30.2100, 29.8600, 29.9500, 30.0900, 30.2100, 30.2000, 30.1800,\n",
      "        30.2000, 30.2700, 30.1800, 30.1800, 29.9300, 30.1200, 30.2000, 30.1200,\n",
      "        29.9600, 30.2000, 30.2000, 29.8500, 30.1200, 30.1200, 30.2100, 29.9600,\n",
      "        29.9300, 30.1800, 29.9600, 30.0200, 29.9600, 30.2700, 30.2000, 30.1800])\n",
      "tensor([23.3224, 25.5949, 23.1670, 25.3952, 23.5958, 23.4440, 27.9381, 22.3106,\n",
      "        23.4160, 27.5503, 26.2615, 25.3041, 25.0339, 24.1332, 30.9447, 20.2273,\n",
      "        22.9862, 23.6702, 22.6703, 25.4975, 27.2241, 24.2516, 26.0247, 20.4091,\n",
      "        24.9624, 24.2757, 24.1092, 25.3664, 19.8136, 20.7406, 21.4449, 20.0784],\n",
      "       grad_fn=<SqueezeBackward0>) tensor([30.0900, 30.0200, 30.1200, 30.1800, 30.2100, 29.9300, 30.1200, 30.1800,\n",
      "        30.2700, 30.0200, 30.1200, 30.2100, 30.2700, 30.1800, 29.9600, 30.1200,\n",
      "        29.9300, 30.1200, 30.1800, 29.9600, 29.9300, 29.9600, 29.9300, 29.9600,\n",
      "        29.9500, 29.8600, 30.1800, 30.1200, 30.1800, 30.2000, 29.9300, 30.1800])\n",
      "tensor([23.7830, 28.6045, 25.4084, 29.7641, 27.8598, 30.0959, 31.1818, 29.1717,\n",
      "        30.2827, 23.6196, 26.9728, 29.0172, 33.9802, 25.6954, 31.1822, 29.6089,\n",
      "        25.6392, 26.1977, 35.4087, 31.0205, 35.3758, 28.2708, 30.7365, 28.4019,\n",
      "        29.6775, 29.4279, 31.6096, 29.8377, 24.5710, 29.8395, 30.8567, 30.3939],\n",
      "       grad_fn=<SqueezeBackward0>) tensor([30.2000, 29.9300, 29.9600, 30.1200, 30.1200, 30.2700, 30.1200, 30.1200,\n",
      "        29.9600, 29.9600, 29.9300, 29.9600, 29.9300, 30.1200, 29.9600, 30.1200,\n",
      "        30.1800, 30.1800, 30.2100, 30.1200, 30.0200, 30.1200, 30.1800, 30.1800,\n",
      "        30.2000, 29.9500, 30.0900, 29.9300, 30.1200, 30.1800, 29.9500, 30.1800])\n",
      "tensor([28.5028, 29.7767, 29.4380, 34.3489, 29.3060, 29.8868, 27.1283, 30.7616,\n",
      "        25.8349, 27.6552, 28.6910, 29.4910, 29.7101, 30.4292, 30.2656, 22.6391,\n",
      "        25.3394, 35.5971, 33.3180, 27.7553, 29.4823, 31.7072, 33.7944, 34.8599,\n",
      "        29.1832, 27.7168, 23.7760, 33.1997, 30.8068, 30.7959, 27.4034, 29.4638],\n",
      "       grad_fn=<SqueezeBackward0>) tensor([29.9300, 29.9600, 30.2000, 30.0900, 30.2000, 30.3100, 30.2000, 30.1200,\n",
      "        29.9600, 30.1800, 30.2100, 30.2000, 30.0900, 30.2000, 29.9600, 29.9300,\n",
      "        29.9600, 29.9300, 29.9600, 29.9300, 30.1800, 30.1800, 29.9600, 29.8500,\n",
      "        29.9300, 29.9600, 30.1800, 29.9600, 30.1800, 30.2000, 29.9300, 30.2000])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model, test_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 17\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(lr, batch_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     16\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m   \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m   best_model, best_loss \u001b[38;5;241m=\u001b[39m test(test_dataloader, model, loss_fn, best_loss, best_model)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      5\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Compute prediction error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/jupyter_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/jupyter_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/jupyter_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/jupyter_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m, in \u001b[0;36mCoralDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m sst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssts[idx]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 17\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, sst\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/jupyter_env/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/jupyter_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/jupyter_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/jupyter_env/lib/python3.10/site-packages/torchvision/transforms/transforms.py:354\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/jupyter_env/lib/python3.10/site-packages/torchvision/transforms/functional.py:477\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    476\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/jupyter_env/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/jupyter_env/lib/python3.10/site-packages/PIL/Image.py:2328\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2317\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2318\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[1;32m   2319\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2320\u001b[0m         )\n\u001b[1;32m   2321\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2322\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2323\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2324\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2325\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2326\u001b[0m         )\n\u001b[0;32m-> 2328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model, test_dataloader = train_model(0.001)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
